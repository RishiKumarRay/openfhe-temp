name: 'A custom GitHub actions pipeline that wrappedup build, unit_test, beanchmark and extract stages'
description: 'composite github actions'
inputs:
  module_name:
    description: 'Name of the module'
    required: true
    default: 'default'
  cmake-args:
    description: 'Argument for cmake command'
    required: true
    default: '-DBUILD_EXTRAS=ON -DWITH_TCM=Y -DMATHBACKEND=4'
  run_beanchmark:
    description: 'Run Beanchmark stages'
    required: false
  run_tcm:
    description: 'Run tcm stages'
    required: false
  run_extras:
    description: 'Run allextras stages'
    required: false

runs:
  using: "composite"
  steps:

    # build
    - name: '${{ inputs.module_name }}_build'
      shell: bash
      run: |
        whoami
        mkdir -p build
        cd build
        cmake ${{ inputs.cmake-args }}
        # run only if run_tcm input is set
        if ${{ input.run_tcm }}; then
          make tcm
        fi
        make -j $(nproc) all
        # run only if run_extra input is set
        if ${{ input.run_extras }}; then
          make allextras 
        fi

    # binfhe
    - name: '${{ inputs.module_name }}_test_binfhe'
      shell: bash
      run: |
        pwd
        echo $LD_LIBRARY_PATH
        build/unittest/binfhe_tests --gtest_output=xml

    # test_core
    - name: '${{ inputs.module_name }}_test_core'
      shell: bash
      run: |
        pwd
        echo $LD_LIBRARY_PATH
        build/unittest/core_tests --gtest_output=xml

    # test_pke
    - name: '${{ inputs.module_name }}_test_pke'
      shell: bash
      run: |
        pwd
        echo $LD_LIBRARY_PATH
        build/unittest/pke_tests --gtest_output=xml

    # beanchmark
    - name: benchmark_basic
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/basic_test --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_binfhe_ap
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/binfhe-ap --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_binfhe_ginx
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/binfhe-ginx --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_encoding
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/Encoding --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_integermath
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/IntegerMath --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_lattice
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/Lattice --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_lib
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/lib-benchmark --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_nbtheory
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/NbTheory --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_poly_1k
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/poly-benchmark-1k --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_poly_4k_
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/poly-benchmark-4k --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_poly_16k
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/poly-benchmark-16k --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv
    - name: benchmark_vectormath
      shell: bash
      if: ${{ inputs.run_beanchmark }}
      run: |
        build/bin/benchmark/VectorMath --benchmark_out="${CI_JOB_NAME}_${CI_COMMIT_SHA}" --benchmark_out_format=csv

    # extract
    - name: '${{ inputs.module_name }}_extras_core'
      shell: bash
      run: |
        ./build/bin/extras/core/dft
        ./build/bin/extras/core/math
        ./build/bin/extras/core/ntt1
        ./build/bin/extras/core/ntt2
    
    # cleanup
    # - name: '${{ inputs.module_name }}_cleanup'
    #   shell: bash
    #   run: rm -rf build